#!/usr/bin/env python
##
# Copyright 2017 Sam Wen.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##
# prepare parameters, upload files to s3 bucket and create 3 stacks: resources, database and dataservice
#
import sys
import json
import os
import time

import utils

config = {}

project_dir = os.path.dirname((os.path.dirname(os.path.abspath(__file__))))
os.chdir(project_dir) 

if not os.path.exists('tmp'):
    utils.run('mkdir -p tmp', '')

utils.launch_parse_args(config)

verbose = config['verbose']
del(config['verbose'])

if not 'JAR_FILE' in config:
    config['JAR_FILE'] = 'server-1.0.0.jar'

argv_email = ''
if 'email' in config:
    argv_email = config['email']
    del(config['email'])

#############################################################################################
# work on resources stack
#
stack_name = 'resources'

stack_status = utils.check_stack(stack_name)

if stack_status == 'NOT_EXISTS':
    params = utils.prepare_parameters(argv_email)
    if verbose > 1:
        print(json.dumps(params, indent=4, sort_keys=True))

template = 'resources.yaml'
stack_status = utils.create_stack(stack_name, template, True)

if stack_status != 'CREATE_COMPLETE':
    print('Failed! '+stack_status)
    sys.exit(1)

#############################################################################################
# work on database stack
#
if not 'DB_HOST_NAME' in config  or \
   not 'DB_USER_NAME' in config or \
   not 'DB_USER_PASS' in config:

    stack_name = 'database'

    template = 'ec2-mysql.yaml'
    stack_status = utils.create_stack(stack_name, template, False)

    if stack_status != 'CREATE_COMPLETE':
        print('Failed! '+stack_status)
        sys.exit(1)

#############################################################################################
# work on s3 upload
#
configfile ='deployment/configure'
utils.make_config_file(config, configfile)

# sync packages with s3 bucket
cmd = 'aws s3 sync s3-upload/packages s3://' + config['S3_BUCKET'] + '/packages --exclude \'.*\''
utils.run(cmd, '')

if not os.path.exists('deployment/lib/'+config['JAR_FILE']):
    config['JAR_FILE'] = 'server-1.0.0.jar'
    cmd = 'cp /lib-default/server-1.0.0.jar deployment/lib'
    utils.run(cmd, '')

utils.package_and_upload_to_s3_bucket('cd-install')

#############################################################################################
# work on dataservice stack
#
stack_name = 'dataservice'

template = 'autoscaling-elastic-loadbalance-codedeploy.yaml'
stack_status = utils.create_stack(stack_name, template, False)

if stack_status != 'CREATE_COMPLETE':
    print('Failed! '+stack_status)
    sys.exit(1)

utils.make_update_deployment_group('Dataservice-CDG-Update')

#############################################################################################
# get URL, move all files in ./tmp/folder to a timestamped sub folder
#
jsonfile = 'tmp/' + stack_name + '-result.json'
url = ''
with open(jsonfile) as data_file:
    data = json.load(data_file)
for output in data['Stacks'][0]['Outputs']:
    if output['OutputKey'] == 'URL':
        url = output['OutputValue']
        break

saved_folder = 'tmp/' + time.strftime('%Y%m%d-%H%M%S')
os.makedirs(saved_folder, exist_ok=True)
utils.run_exit_code('mv tmp/*.json '+ saved_folder, '')
utils.run_exit_code('mv tmp/*.text '+ saved_folder, '')

if url != '':
    print('Done!')
    print('\nURL: '+url+'\n')
